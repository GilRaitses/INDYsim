% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
  letterpaper,
]{article}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp}
\else
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\RequirePackage{ifxetex}
\RequirePackage{ifluatex}
\usepackage{lmodern}
\ifPDFTeX\else
\fi
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{%
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath}
}{}
\makeatletter
\@ifundefined{KOMAClassName}{%
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{longtable,booktabs,array}
\usepackage{calc}
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{%
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox\pandoc@box%
  \fi%
}
\def\fps@figure{htbp}
\makeatother

\setlength{\emergencystretch}{3em}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{}
\urlstyle{same}
\hypersetup{
  pdftitle={Individual-level behavioral phenotyping in \textit{Drosophila} larvae using simulation-based inference: Supplementary Material},
  pdfauthor={Gil Raitses; Mirna Mihovilovic Skanata},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Individual-level behavioral phenotyping in \textit{Drosophila} larvae using simulation-based inference: Supplementary Material}
\author{Gil Raitses \and Mirna Mihovilovic Skanata}
\date{}
\begin{document}
\maketitle

\section*{Supplementary Methods}

\subsection*{Simulation Parameters}

[Details of simulation parameters will be added here]

\subsection*{Kernel Fitting Details}

[Detailed kernel fitting procedures and optimization parameters]

\subsection*{Clustering Algorithm Details}

[Detailed clustering parameters and validation metrics]

\section*{Supplementary Results}

\subsection*{Individual Track Kernel Fits}

[Summary statistics of individual kernel fits]

\subsection*{Cross-Validation Results}

[Detailed cross-validation results tables]

\subsection*{Clustering Stability Metrics}

[Detailed clustering stability analysis]

\section*{Supplementary Figures}

[Supplementary figures will be added here]

\section*{Computational Field Notes}

This section documents implementation decisions made during the analysis pipeline development, with emphasis on preserving statistical rigor.

\subsection*{GPU Vectorization for Power Analysis}

\paragraph{Initial serial implementation.}
The power analysis was initially implemented in sequential Python (NumPy/SciPy). After 9+ hours of CPU execution, only 2 of 8 event-count conditions had completed. Projected total runtime exceeded 70 hours, making this approach impractical. The serial script was terminated and reimplemented for GPU execution. This section documents the reimplementation to confirm that statistical rigor was preserved.

\paragraph{Computational requirements.}
The simulation-based power analysis (main text, Methods: Power Analysis) requires fitting 100 population tracks $\times$ 100 fast-responder tracks $\times$ 8 event counts $\times$ 50 bootstrap replicates $= 800{,}000$ model fits. Sequential CPU execution was estimated at $>$70 hours.

To accelerate computation, the pipeline was migrated to GPU using JAX with full vectorization. This implementation choice maintains 100\% statistical equivalence to sequential execution:

\begin{itemize}
    \item \textbf{Simulation fidelity}: Each track is simulated from the same gamma-difference kernel model with reproducible random seeds via JAX's PRNG key splitting.
    \item \textbf{Optimization equivalence}: MLE optimization uses identical objective functions (log-likelihood with integral term) and convergence criteria.
    \item \textbf{Bootstrap procedure}: Parametric bootstrap samples are generated identically---simulate from fitted parameters, refit, collect parameter estimates.
    \item \textbf{CI calculation}: Confidence intervals computed as 2.5th--97.5th percentiles of bootstrap distributions.
    \item \textbf{Error rate definitions}: Type~I error = proportion of population tracks whose CI excludes true $\tau_1$; Power = proportion of fast-responder tracks whose CI excludes population mean.
\end{itemize}

The only difference is \textit{execution strategy}: \texttt{vmap(process\_track)(keys)} processes all 100 tracks in parallel on GPU, whereas a Python \texttt{for} loop processes them sequentially on CPU. Mathematically, these are identical---\texttt{vmap} is a parallel map operator with no side effects that could alter results.

Random number handling ensures reproducibility:
\begin{verbatim}
key = PRNGKey(42)
keys = split(key, 100)
# Sequential: for i in range(100): simulate(keys[i])
# Vectorized: vmap(simulate)(keys)  # Same keys, same results
\end{verbatim}

Final runtime with GPU vectorization: $\sim$30 minutes (Tesla T4) vs $>$70 hours (CPU sequential), a $>$140$\times$ speedup with zero impact on statistical validity.

\subsection*{Event Definition Verification}

During validation pipeline development, a critical inconsistency was identified: some scripts used \texttt{klein\_run\_table/time0} (run start times) while others used \texttt{is\_reorientation\_start} (reorientation onset times). These are distinct events:
\begin{itemize}
    \item \textbf{Run start}: The larva begins a forward locomotion bout.
    \item \textbf{Reorientation onset}: The larva transitions from run to turn (the event modeled by the kernel).
\end{itemize}

All pipelines were verified to use \texttt{is\_reorientation\_start} consistently, matching the event definition in the original study.

\subsection*{Multi-Start Optimization}

The 6-parameter gamma-difference kernel produces a non-convex likelihood surface. Initial implementations used single-start optimization, which converged to local minima in $\sim$15--20\% of tracks, producing qualitatively incorrect kernel shapes (e.g., inverted polarity, implausible time constants).

The corrected implementation uses grid search initialization:
\begin{itemize}
    \item $\tau_1 \in \{0.3, 0.6, 0.9\}$~s
    \item $\tau_2 \in \{1.0, 2.0, 3.0\}$~s  
    \item $A/B \in \{1.0, 2.0\}$
\end{itemize}
yielding 18 initial points. The solution with highest final log-likelihood was retained.

\subsection*{Structural Identifiability Analysis}

During power analysis debugging, a fundamental structural identifiability issue was discovered that explains the difficulty of individual-level kernel fitting.

\paragraph{The problem.} The gamma-difference kernel with population parameters $A = 1.5$ and $B = 12.0$ produces a predominantly \textit{inhibitory} response: $K(t) < 0$ for $t > 0.2$~s during LED-ON. This means:
\begin{enumerate}
    \item Events are \textit{suppressed} during LED-ON relative to LED-OFF.
    \item Only $\sim$20\% of events occur during LED-ON, despite LED-ON comprising 33\% of the stimulus cycle.
    \item A typical track has only $\sim$2 events in the LED-ON window where $\tau_1$ information is concentrated.
\end{enumerate}

\paragraph{Diagnostic evidence.} Likelihood surface analysis revealed that the log-likelihood is nearly flat across a wide range of $\tau_1$ values. For a representative track with 11 total events (2 in LED-ON):
\begin{verbatim}
True tau1 = 0.63s
LL at tau1=0.63: -53.98
LL at tau1=1.50: -53.83 (HIGHER - MLE converges here)
Fitted tau1: 1.87s (3x too high)
\end{verbatim}
The MLE finds a spuriously high $\tau_1$ because the likelihood difference between true and incorrect values is smaller than stochastic variation.

\paragraph{Why longer tracks do not help.} The ratio of informative (LED-ON) to uninformative (LED-OFF) events is determined by the stimulus protocol and kernel shape, not by track duration. Extending recordings from 20 to 80 minutes would increase total events proportionally, but the $\sim$20\% informative fraction would remain constant. The Fisher information for $\tau_1$ grows only with informative events in the LED-ON window.

\paragraph{Implications.} This finding validates the manuscript's conclusion that individual $\tau_1$ estimation is not feasible under the current experimental design. The problem is structural (kernel parameterization + stimulus protocol) rather than merely data sparsity. Resolution would require either:
\begin{itemize}
    \item Modified experimental design (higher duty cycle, pulse trains), or
    \item Simplified model (only $\tau_1$ varies by individual; other parameters fixed at population values).
\end{itemize}

\section*{Code Availability}

All analysis code is available at \url{https://github.com/GilRaitses/indysim} in the \texttt{scripts/2025-12-16/phenotyping\_followup/code/} directory.

\end{document}


